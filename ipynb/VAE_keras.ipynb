{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import imageio,os\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "import pywt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "latent_dim=10\n",
    "epochs=5\n",
    "num_classes=10\n",
    "img_dim=28\n",
    "filters=16\n",
    "intermediate_dim=256\n",
    "\n",
    "BatchNorm = True  # 是否批量归一化\n",
    "number = 3000  # 每类样本的数量  1000:0.32,  10000:0.68,  20000:0.7105   30000:81\n",
    "length =6400   # 信号长度  16384=128*128\n",
    "normal = False  # 是否标准化\n",
    "enc=True     #256000/6400=40  小于3000，所以要做数据增强\n",
    "enc_step=500\n",
    "rate = [0.8, 0.1, 0.1]  # 训练集验证集测试集划分比例,之和为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.87390052e-01,  1.31929260e-01,  4.03487884e-03, ...,\n",
       "         -4.46530455e-02,  1.73153035e-01,  3.53758163e-01],\n",
       "        [-2.50287650e-01, -3.34760777e-01, -3.66257926e-01, ...,\n",
       "         -3.54357103e-01, -3.48543772e-01,  2.20779644e-01],\n",
       "        [-1.70730264e-01, -1.67021170e-01,  1.25644519e-01, ...,\n",
       "          3.05195135e-01, -1.39077269e-01,  1.91880501e-01],\n",
       "        ...,\n",
       "        [ 9.74367600e-01,  3.91415407e-01,  3.58067202e+00, ...,\n",
       "          3.88795892e-01, -6.28241285e-02,  3.53436582e-01],\n",
       "        [-3.35462739e-01,  4.14124840e-01,  2.47490806e-01, ...,\n",
       "         -2.49097091e-01,  5.54905144e-01, -2.00582212e-01],\n",
       "        [ 1.45483618e-01,  5.03346975e-01,  2.36521009e-01, ...,\n",
       "         -6.11545957e-01, -2.88709381e-01,  5.21026667e-01]],\n",
       "\n",
       "       [[-8.83390133e-02, -1.52817191e-01,  1.85012261e-02, ...,\n",
       "          3.69499095e-03,  3.08133197e-02,  1.21822408e-01],\n",
       "        [-1.22209125e-01,  1.89755365e-04, -6.10989451e-02, ...,\n",
       "          1.18404354e-02,  3.58262112e-01, -3.06630631e-01],\n",
       "        [-2.23145477e-01,  6.04952219e-02,  1.62133279e-01, ...,\n",
       "          2.14367700e-01,  2.31995476e-01,  2.96059840e-01],\n",
       "        ...,\n",
       "        [-1.85904086e+00, -2.58756074e+00,  2.97520108e-01, ...,\n",
       "         -9.99049224e-02,  9.44906863e-03, -3.56253183e-02],\n",
       "        [-1.86260426e-01, -3.81806832e-02,  7.82061933e-02, ...,\n",
       "          7.86431310e-01,  2.33968882e-01, -2.56283556e-01],\n",
       "        [ 3.79140006e-01,  9.23980134e-02, -5.93383287e-02, ...,\n",
       "         -5.29883920e-02,  1.34787733e-01,  2.57490558e-02]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.load('./data_set/test_x.npy')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1 加载据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7da9e8679306>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_dim' is not defined"
     ]
    }
   ],
   "source": [
    "(x_train, y_train_), (x_test, y_test_) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((-1, img_dim, img_dim, 1))\n",
    "x_test = x_test.reshape((-1, img_dim, img_dim, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train_.shape)\n",
    "print(x_test.shape)\n",
    "y_train_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1加载振动信号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: F:\\paderborn dataset\\start_data\\training_dataset\\N09_M07_F10\\all\n",
      "test_path: F:\\paderborn dataset\\start_data\\training_dataset\\N09_M07_F10\\all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\app\\anaconda20183\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\app\\anaconda20183\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ train_one-hot \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
      "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ test_one-hot \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 6400 to array axis with dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5ddc88c65b98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"F:\\paderborn dataset\\start_data\\training_dataset\\N09_M07_F10\\all\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpath_testing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"F:\\paderborn dataset\\start_data\\training_dataset\\N09_M07_F10\\all\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_valid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_path1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_testing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\CODE_TRUE\\ipynb\\preprocess.py\u001b[0m in \u001b[0;36mprepro\u001b[1;34m(d_path, d_path1, length, number, normal, rate, enc, enc_step)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;31m# 需要做一个数据转换，转换成np格式.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mTrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mTest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;31m# Train_X_OUT = np.asarray(Train_X_OUT)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\app\\anaconda20183\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot copy sequence with size 6400 to array axis with dimension 2"
     ]
    }
   ],
   "source": [
    "path_training = r\"F:\\paderborn dataset\\start_data\\training_dataset\\N09_M07_F10\\all\"\n",
    "path_testing = r\"F:\\paderborn dataset\\start_data\\training_dataset\\N09_M07_F10\\all\"\n",
    "x_train1, y_train1, x_valid1, y_valid1, x_test1, y_test1=preprocess.prepro(d_path=path_training,d_path1=path_testing, length=length,number=number,normal=normal,rate=rate,enc=enc, enc_step=enc_step)\n",
    "print(x_train1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义小波函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wt_f(data,wavelet='db2',mode='symmetric',maxlevel=3):\n",
    "    wp_out=pywt.WaveletPacket(data,wavelet,mode,maxlevel)\n",
    "    a=wp_out['a'].data\n",
    "    b=wp_out['d'].data\n",
    "    return wp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16800, 6400, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6400, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x=x_train1[1,:]\n",
    "x_train, x_valid, x_test = x_train1[:, :, np.newaxis], x_valid1[:, :, np.newaxis], x_test1[:, :, np.newaxis]\n",
    "# 输入数据的维度  input_shape是静态的\n",
    "input_shape = x_train.shape[1:]\n",
    "print(x_train.shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3201,)\n",
      "(3201,)\n",
      "(802,)\n",
      "**************************************************\n",
      "(1602,)\n",
      "(6402,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X=plot_data.reshape(len(plot_data),).tolist()\n",
    "wp=wt_f(data=x,wavelet='db2',mode='symmetric',maxlevel=3)\n",
    "print(wp['a'].data.shape)     \n",
    "print(wp['d'].data.shape)  \n",
    "\n",
    "wp_1=wt_f(data=wp['a'].data,wavelet='db2',mode='symmetric',maxlevel=3)\n",
    "print(wp_1['aa'].data.shape)\n",
    "print('*'*50)\n",
    "\n",
    "new_wp = pywt.WaveletPacket(data=None, wavelet='db2', mode='symmetric')\n",
    "new_wp['aa'] = wp['aa']#低频信号\n",
    "print(wp['aa'].data.shape)     \n",
    "new_wp['ad'] = wp['ad']#高频信号0.0\n",
    "new_wp['da'] = wp['da']#低频信号\n",
    "new_wp['dd'] = wp['dd']#高频信号\n",
    "a=new_wp.reconstruct(update=True)\n",
    "print(a.shape)\n",
    "plt.plot(range(len(a)),a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dim1=80\n",
    "# print(x_train1.shape)\n",
    "# print(x_test1.shape)\n",
    "# print(x_valid1.shape)\n",
    "# print(y_train1)\n",
    "# print('*'*50)\n",
    "# x_train = x_train1.reshape((-1, img_dim1, img_dim1, 1))\n",
    "# x_valid = x_valid1.reshape((-1, img_dim1, img_dim1, 1))\n",
    "# x_test = x_test1.reshape((-1, img_dim1, img_dim1, 1))\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积（编码器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\app\\anaconda20183\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Conv2DTranspose(filters=filters,kernel_size=3,strides=1,padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(LeakyReLU(0.2))\n",
    "\n",
    "# model.add(Conv2DTranspose(filters=filters,kernel_size=3,strides=1,padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(LeakyReLU(0.2))\n",
    "x=Input(shape=(img_dim,img_dim,1))\n",
    "h=x\n",
    "filters*=2\n",
    "h=Conv2DTranspose(filters=filters,kernel_size=3,strides=2,padding='same')(h)\n",
    "h=MaxPooling2D(pool_size=2)(h)\n",
    "h=ELU(0.2)(h)\n",
    "h=Conv2DTranspose(filters=filters,kernel_size=3,strides=1,padding='same')(h)\n",
    "h=MaxPooling2D(pool_size=2)(h)\n",
    "h=ELU(0.2)(h)\n",
    "filters //= 2\n",
    "h=Conv2DTranspose(filters=filters,kernel_size=3,strides=2,padding='same')(h)\n",
    "h=MaxPooling2D(pool_size=2)(h)\n",
    "h=ELU(0.2)(h)\n",
    "h=Conv2DTranspose(filters=filters,kernel_size=3,strides=1,padding='same')(h)\n",
    "h=MaxPooling2D(pool_size=2)(h)\n",
    "h=ELU(0.2)(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征拾取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h4=h\n",
    "h = ELU(0.2)(h4)\n",
    "h_shape = K.int_shape(h)[1:]\n",
    "h = Flatten()(h)\n",
    "z_mean = Dense(latent_dim)(h) # p(z|x)的均值\n",
    "z_log_var = Dense(latent_dim)(h) # p(z|x)的方差\n",
    "encoder = Model(x, z_mean) # 通常认为z_mean就是所需的隐变量编码\n",
    "z = Input(shape=(latent_dim,))\n",
    "h = z\n",
    "h = Dense(np.prod(h_shape))(h)\n",
    "h = Reshape(h_shape)(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 反卷积（解码器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters=16\n",
    "filters*=2\n",
    "h = Conv2DTranspose(filters=filters,kernel_size=3,strides=1,padding='same')(h)\n",
    "#     h=MaxPooling2D(pool_size=2)(h)\n",
    "h = ELU(0.2)(h)\n",
    "h = Conv2DTranspose(filters=filters,kernel_size=3,strides=2,padding='same')(h)\n",
    "#     h=MaxPooling2D(pool_size=2)(h)\n",
    "h = ELU(0.2)(h)\n",
    "filters //= 2\n",
    "h = Conv2DTranspose(filters=filters,kernel_size=3,strides=1,padding='same')(h)\n",
    "#     h=MaxPooling2D(pool_size=2)(h)\n",
    "h = ELU(0.2)(h)\n",
    "h = Conv2DTranspose(filters=filters,kernel_size=3,strides=2,padding='same')(h)\n",
    "#     h=MaxPooling2D(pool_size=2)(h)\n",
    "h = ELU(0.2)(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = Conv2DTranspose(filters=1,kernel_size=3,activation='sigmoid',padding='same')(h)\n",
    "decoder = Model(z, x_recon) # 解码器\n",
    "generator = decoder\n",
    "\n",
    "z = Input(shape=(latent_dim,))\n",
    "y = Dense(intermediate_dim, activation='relu')(z)\n",
    "y = Dense(num_classes, activation='softmax')(y)\n",
    "classfier = Model(z, y) # 隐变量分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重参数技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# 重参数层，相当于给输入加入噪声\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "x_recon = decoder(z)\n",
    "y = classfier(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(Layer):\n",
    "    \"\"\"这是个简单的层，定义q(z|y)中的均值参数，每个类别配一个均值。\n",
    "    然后输出“z - 均值”，为后面计算loss准备。\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        self.num_classes = num_classes\n",
    "        super(Gaussian, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        latent_dim = input_shape[-1]\n",
    "        self.mean = self.add_weight(name='mean',shape=(self.num_classes, latent_dim),initializer='zeros')\n",
    "    def call(self, inputs):\n",
    "        z = inputs # z.shape=(batch_size, latent_dim)\n",
    "        z = K.expand_dims(z, 1)\n",
    "        return z - K.expand_dims(self.mean, 0)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_classes, input_shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 56, 56, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 32)   0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 28, 28, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 32)   9248        elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 32)   0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 14, 14, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 28, 28, 16)   4624        elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 14, 14, 16)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 14, 14, 16)   2320        elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 16)     0           conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 7, 7, 16)     0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 7, 7, 16)     0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 28, 28, 1)    29601       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_1 (Gaussian)           (None, 10, 10)       100         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 10)           5386        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 67,299\n",
      "Trainable params: 67,299\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Error when checking model target: expected no data, but got:', array([5, 0, 4, ..., 5, 6, 8], dtype=uint8))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5de3154cec91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'vae_keras_cluster.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\app\\anaconda20183\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\app\\anaconda20183\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\app\\anaconda20183\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     61\u001b[0m             raise ValueError('Error when checking model ' +\n\u001b[0;32m     62\u001b[0m                              \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                              'expected no data, but got:', data)\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Error when checking model target: expected no data, but got:', array([5, 0, 4, ..., 5, 6, 8], dtype=uint8))"
     ]
    }
   ],
   "source": [
    "gaussian = Gaussian(num_classes)\n",
    "z_prior_mean = gaussian(z)\n",
    "\n",
    "\n",
    "# 建立模型\n",
    "vae = Model(x, [x_recon, z_prior_mean, y])\n",
    "\n",
    "# 下面一大通都是为了定义loss\n",
    "z_mean = K.expand_dims(z_mean, 1)\n",
    "z_log_var = K.expand_dims(z_log_var, 1)\n",
    "\n",
    "lamb = 2.5 # 这是重构误差的权重，它的相反数就是重构方差，越大意味着方差越小。\n",
    "xent_loss = 0.5 * K.mean((x - x_recon)**2, 0)\n",
    "kl_loss = - 0.5 * (z_log_var - K.square(z_prior_mean))\n",
    "kl_loss = K.mean(K.batch_dot(K.expand_dims(y, 1), kl_loss), 0)\n",
    "cat_loss = K.mean(y * K.log(y + K.epsilon()), 0)\n",
    "vae_loss = lamb * K.sum(xent_loss) + K.sum(kl_loss) + K.sum(cat_loss)\n",
    "\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "vae.fit(x_train,shuffle=True,epochs=epochs,batch_size=batch_size,validation_data=(x_test, None),verbose=2)\n",
    "plot_model(model=vae, to_file='vae_keras_cluster.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import to_categorical\n",
    " \n",
    "labels = y_test_\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels) # transfer label to binary value\n",
    "labels = to_categorical(labels) # transfer binary label to one-hot. IMPORTANT\n",
    "score = vae.evaluate(x=x_test,y=labels, batch_size=128)\n",
    "# y_test_.shape\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = K.eval(gaussian.mean)\n",
    "x_train_encoded = encoder.predict(x_train)\n",
    "y_train_pred = classfier.predict(x_train_encoded).argmax(axis=1)\n",
    "x_test_encoded = encoder.predict(x_test)\n",
    "y_test_pred = classfier.predict(x_test_encoded).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sample(path, category=0):\n",
    "    \"\"\"观察被模型聚为同一类的样本\n",
    "    \"\"\"\n",
    "    n = 8\n",
    "    print('*'*50)\n",
    "    figure = np.zeros((img_dim * n, img_dim * n))\n",
    "    idxs = np.where(y_train_pred == category)[0]\n",
    "    print(idxs.shape)\n",
    "    print('*'*50)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            digit = x_train[np.random.choice(idxs)]\n",
    "            digit = digit.reshape((img_dim, img_dim))\n",
    "            figure[i * img_dim: (i + 1) * img_dim,\n",
    "            j * img_dim: (j + 1) * img_dim] = digit\n",
    "    imageio.imwrite(path, figure * 255)\n",
    "\n",
    "\n",
    "def random_sample(path, category=0, std=1):\n",
    "    \"\"\"按照聚类结果进行条件随机生成\n",
    "    \"\"\"\n",
    "    n = 8\n",
    "    figure = np.zeros((img_dim * n, img_dim * n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            noise_shape = (1, latent_dim)\n",
    "            z_sample = np.array(np.random.randn(*noise_shape)) * std + means[category]\n",
    "#             通过随机生成z_sample，解码x_recon\n",
    "            x_recon = generator.predict(z_sample)\n",
    "            digit = x_recon[0].reshape((img_dim, img_dim))\n",
    "            figure[i * img_dim: (i + 1) * img_dim,\n",
    "            j * img_dim: (j + 1) * img_dim] = digit\n",
    "    imageio.imwrite(path, figure * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('samples'):\n",
    "    os.mkdir('samples')\n",
    "\n",
    "for i in range(10):\n",
    "    cluster_sample(u'samples/聚类类别_%s.png' % i, i)\n",
    "    random_sample(u'samples/类别采样_%s.png' % i, i)\n",
    "    \n",
    "right = 0.\n",
    "for i in range(10):\n",
    "    print('%'*50)\n",
    "    print(y_train_)\n",
    "    print('%'*50)\n",
    "    _ = np.bincount(y_train_[y_train_pred == i])\n",
    "    right += _.max()\n",
    "\n",
    "print ('train acc: %s' % (right / len(y_train_)))\n",
    "\n",
    "\n",
    "right = 0.\n",
    "for i in range(10):\n",
    "    _ = np.bincount(y_test_[y_test_pred == i])\n",
    "    right += _.max()\n",
    "\n",
    "print ('test acc: %s' % (right / len(y_test_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
